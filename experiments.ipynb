{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848a23da-cea2-4f84-ac33-e288a8f527cf",
   "metadata": {},
   "source": [
    "# Single Iteration C Code APR Using LLM Experiments\n",
    "\n",
    "Find out what a good ESBMC single iteration APR prompt contains. \n",
    "\n",
    "## Methodology\n",
    "\n",
    "True random select 100 random samples of Expanded NeuroCodeBench that have `VERIFICATION FAILED`.\n",
    "\n",
    "Run each sample through GPT-3.5 Turbo with each prompt.\n",
    "\n",
    "Total Experiments:\n",
    "* We have the following to groups of prompt templates:\n",
    "  * simple_prompts_no_esbmc\n",
    "  * simple_prompts\n",
    "  * simple_prompts_flipped\n",
    "  * persona_prompt_no_esbmc\n",
    "  * persona_prompt\n",
    "  * persona_prompt_flipped\n",
    "  * Each group has 2 prompt templates inside.\n",
    "* We have 6 roles per persona group template.\n",
    "* We have 100 experiments.\n",
    "* ~~We have to run experiments once for contextual and n for constant.~~\n",
    "* We have to run each experiment twice, one for violated property ESBMC output and one for counterexample ESBMC output.\n",
    "* Simple Prompt: `100 * 3 * 2 = 600`\n",
    "* Persona Prompt: `100 * 3 * 6 * 2 * 2 = 7200`\n",
    "* Total: `7800`\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "See the evaluation notebook.\n",
    "\n",
    "## Generated Files\n",
    "\n",
    "This notebook will use:\n",
    "\n",
    "* `samples`\n",
    "* `esbmc_output`\n",
    "\n",
    "This notebook will generate the following folders:\n",
    "\n",
    "* `results`\n",
    "* `samples-patched`\n",
    "\n",
    "Notice:\n",
    "\n",
    "* `includes` is used by the `eval-esbmc.sh` script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ff471-c0da-4bed-916e-5ca3f0008a8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Obtaining Samples\n",
    "\n",
    "Get true random filenames. Run the `get_filenames.sh` script to get the filenames of all the `VERIFICATION FAILED` samples. The filenames should be saved in `./all_sample_names`. The following section of code randomly selects 100 samples and places the result in `./selected_sample_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e118fb5-dad9-4949-82df-5d37b2b80bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05c683ac-3cec-4d84-b174-b0d99f56e59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./all_sample_names\", \"r\") as file:\n",
    "    lines: list[str] = file.readlines()\n",
    "\n",
    "selected_lines: set[str] = set()\n",
    "while len(selected_lines) < 100:\n",
    "    selected_lines.add(choice(lines))\n",
    "\n",
    "len(selected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ea1d0f3-077d-4443-932f-6f6a821b930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./selected_sample_names\", \"w\") as file:\n",
    "    for filename in selected_lines:\n",
    "        file.write(filename)\n",
    "\n",
    "with open(\"./selected_esbmc_output_names\", \"w\") as file:\n",
    "    for filename in selected_lines:\n",
    "        file.write(f\"{filename.strip()}.stdout.txt\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaafbf2-4c99-414f-9232-6829d6e3ae80",
   "metadata": {},
   "source": [
    "### Getting Samples\n",
    "\n",
    "Run `./get_selected_samples` will get the source code of each file listed in `./selected_sample_names` along with the ESBMC output. The content will be placed in `samples` and `esbmc_output` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28486c-7d18-4a58-997a-3e23e08fa444",
   "metadata": {},
   "source": [
    "# Running Experiments with GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dedac7a-275c-4847-9806-6f2e70406f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import TextIOWrapper\n",
    "from time import time\n",
    "from math import floor\n",
    "\n",
    "import tiktoken\n",
    "from time import sleep\n",
    "from typing import Optional\n",
    "from dotenv import get_key as load_dotenv, get_key\n",
    "from openai import OpenAI, Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7c516-52fe-471c-a76c-c73c8980f1e3",
   "metadata": {},
   "source": [
    "### AI Params + Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd485f04-06aa-45e3-9297-73e1588067a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS: int = 16385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75251a83-369f-49aa-864d-73ca679ecb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929dbf01-53f7-49e5-9365-c6f84e3888e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key: Optional[str] = get_key(dotenv_path=\".env\", key_to_get=\"OPENAI_API_KEY\")\n",
    "assert api_key\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f124d75-399d-434e-9e81-2ceb2c340178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_message(prompt: str, source_code: str, esbmc_output: str, role: str) -> str:\n",
    "    return prompt.format_map({\n",
    "        \"source\": source_code,\n",
    "        \"esbmc\": esbmc_output,\n",
    "        \"role\": role,\n",
    "    })\n",
    "\n",
    "def run_sample(prompt: str, source_code: str, esbmc_output: str, role: str) -> list[str]:\n",
    "    message_stack: list = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": get_llm_message(prompt, source_code, esbmc_output, role),\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    response: Completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=message_stack,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ac694-8072-40f1-904a-e27e23ec539e",
   "metadata": {},
   "source": [
    "### Initializing Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6e7c90-55b7-4047-8fc9-7282c04344a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs: list[str] = [\"samples-patched\", \"results\"]\n",
    "\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466cb9f-3ced-49dd-b00a-2d6227e8b867",
   "metadata": {},
   "source": [
    "### Initializing Logger\n",
    "Log everything using these easy custom print and write functions. Need to beware that opening log.txt may display outdated state until buffer is properly flushed. Editing the log file will result in corruption until `log_file.close()` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d39123ba-63c7-42b7-849e-7fffd6855cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close logger\n",
    "try:\n",
    "    if not log_file.closed:\n",
    "        log_file.close()\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ed49b4f-a557-4063-909b-d015c8403f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710896230.8044186: Notice: Starting new logging session.\n"
     ]
    }
   ],
   "source": [
    "# Initialize logger.\n",
    "log_file: TextIOWrapper\n",
    "try:\n",
    "   log_file = open(\"log.txt\", \"a\")\n",
    "except (NameError, ValueError) as e2:\n",
    "    log_file = open(\"log.txt\", \"w\")\n",
    "\n",
    "def log_str(text: str = \"\") -> None:\n",
    "    assert not log_file.closed, \"The log file is closed.\"\n",
    "    if len(text) == 0:\n",
    "        log_file.write(\"\\n\")\n",
    "    else:\n",
    "        log_file.write(f\"Log: {time()}: {text}\\n\")\n",
    "    \n",
    "def print_and_log(text: str = \"\") -> None:\n",
    "    assert not log_file.closed, \"The log file is closed.\"\n",
    "    if len(text) == 0:\n",
    "        log_file.write(\"\\n\")\n",
    "        print()\n",
    "    else:\n",
    "        text = str(time()) + \": \" + text\n",
    "        log_file.write(\"Log: \" + text + \"\\n\")\n",
    "        print(text)\n",
    "\n",
    "print_and_log(\"Notice: Starting new logging session.\")\n",
    "log_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ce12a-11ac-46db-acd9-9f357f20075d",
   "metadata": {},
   "source": [
    "### Load and Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2afab81-8601-4950-95ff-c9dee58d9c6d",
   "metadata": {},
   "source": [
    "#### ESBMC Parsing Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37895ee-c844-48d7-99fa-789b3cfaeb92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### ~~Compress ESBMC Output~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2688d433-2056-4a1c-aa8c-b4b03abd6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esbmc_output_remove_loop_unroll(esbmc_output: str) -> str:\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    kept_lines: list[str] = []\n",
    "    filter: bool = False\n",
    "    for line in lines:\n",
    "        if filter:\n",
    "            if \"Building error trace\" in line:\n",
    "                filter = False\n",
    "                kept_lines.append(line)\n",
    "        else:\n",
    "            if \"Starting Bounded Model Checking\" in line:\n",
    "                filter = True\n",
    "            kept_lines.append(line)\n",
    "    return \"\\n\".join(kept_lines)\n",
    "\n",
    "def esbmc_output_remove_dividers(esbmc_output: str) -> str:\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    kept_lines: list[str] = []\n",
    "    for line in lines:\n",
    "        if \"----------------------------------------------------\" not in line:\n",
    "            kept_lines.append(line)\n",
    "    return \"\\n\".join(kept_lines)\n",
    "\n",
    "def compress_esbmc_output(esbmc_output: str) -> str:\n",
    "    esbmc_output = esbmc_output_remove_loop_unroll(esbmc_output)\n",
    "    esbmc_output = esbmc_output_remove_dividers(esbmc_output)\n",
    "    return esbmc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e2c25-4207-4ee6-a78f-47cb613ebed5",
   "metadata": {},
   "source": [
    "##### ESBMC Extract Parts of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d074dc5-e760-4cee-a01f-105fb2b21aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def esbmc_get_violated_property(esbmc_output: str) -> str:\n",
    "    \"\"\"Gets the violated property line of the ESBMC output.\"\"\"\n",
    "    # Find \"Violated property:\" string in ESBMC output\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    for ix, line in enumerate(lines):\n",
    "        if \"Violated property:\" == line:\n",
    "            return \"\\n\".join(lines[ix:ix+3])\n",
    "    raise Exception(f'Could not find \"Violated property:\" in {file_name_key}')\n",
    "\n",
    "def esbmc_get_counter_example(esbmc_output: str) -> str:\n",
    "    \"\"\"Gets ESBMC output after and including [Counterexample]\"\"\"\n",
    "    idx: int = esbmc_output.find(\"[Counterexample]\\n\")\n",
    "    assert idx != -1\n",
    "    return esbmc_output[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd40aeb1-8372-410a-8338-b5d01fb41f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the samples and esbmc output.\n",
    "subdirs: list[str] = [\"hopfield_nets\", \"poly_approx\", \"reach_prob_density\", \"reinforcement_learning\"]\n",
    "\n",
    "data_samples: dict[str, str] = {}\n",
    "data_esbmc_output: dict[str, str] = {}\n",
    "data_vp_output: dict[str, str] = {}\n",
    "\n",
    "for subdir in subdirs:\n",
    "    files: list[str] = sorted(os.listdir(f\"samples/{subdir}\"))\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".c\"):\n",
    "            continue\n",
    "            \n",
    "        with open(f\"samples/{subdir}/{file_name}\", \"r\") as file:\n",
    "            key: str = f\"{subdir}/{file_name}\"\n",
    "            data_samples[key] = file.read()\n",
    "        with open(f\"esbmc_output/{subdir}/{file_name}.stdout.txt\", \"r\") as file:\n",
    "            esbmc_output: str = file.read()\n",
    "            # data_esbmc_output[key] = esbmc_output\n",
    "            # Parse and remove lines between \"Starting Bounded Model Checking\" until \"Symex completed\"\n",
    "            # data_esbmc_output[key] = compress_esbmc_output(esbmc_output)\n",
    "            data_esbmc_output[key] = esbmc_get_counter_example(esbmc_output)\n",
    "            data_vp_output[key] = esbmc_get_violated_property(esbmc_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24d22a-df07-4222-9ab5-bb109a103737",
   "metadata": {},
   "source": [
    "### Get Code From Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24243e7e-d381-4008-8728-e8a29cd36bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_from_solution(solution: str) -> str:\n",
    "    \"\"\"Strip the source code of any leftover text as sometimes the AI model\n",
    "    will generate text and formatting despite being told not to.\n",
    "    \n",
    "    Source: https://github.com/Yiannis128/esbmc-ai/blob/master/esbmc_ai/solution_generator.py\"\"\"\n",
    "    try:\n",
    "        code_start: int = solution.index(\"```\") + 3\n",
    "        assert code_start != -1\n",
    "        \n",
    "        # Remove up until the new line, because usually there's a language\n",
    "        # specification after the 3 ticks ```c...\n",
    "        code_start = solution.index(\"\\n\", code_start) + 1\n",
    "        assert code_start != -1\n",
    "        \n",
    "        code_end: int = solution[::-1].index(\"```\")\n",
    "        assert code_start != -1\n",
    "        \n",
    "        # -4 = 3 backticks and also the \\n before the backticks.\n",
    "        code_end: int = len(solution) - 4 - code_end\n",
    "        assert code_start <= code_end\n",
    "        \n",
    "        solution = solution[code_start:code_end]\n",
    "    except (ValueError, AssertionError):\n",
    "        pass\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b427f2-73fb-4207-a36a-331c5808be88",
   "metadata": {},
   "source": [
    "### Define Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9740c24c-f1aa-49ea-96ca-32a9cd31ab1b",
   "metadata": {},
   "source": [
    "The following prompts are going to be iterated through. The prompts `simple_prompts_no_esbmc` and `simple_prompts` are the baseline prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e03a862f-e7c1-48e2-bc51-35a2c7f5585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Prompts\n",
    "\n",
    "simple_prompts_no_esbmc: list[str] = [\n",
    "    \"The following source code segment might contain a memory vulnerability\\n\\n```c\\n{source}\\n```\\n\\nFix the source code segment.\",\n",
    "    \"Fix the memory vulnerability that may exist in the in the source code segment:\\n\\n```c\\n{source}\\n```\\n\",\n",
    "]\n",
    "\n",
    "simple_prompts: list[str] = [\n",
    "    \"The following source code contains a memory vulnerability\\n\\n```c\\n{source}\\n```\\n\\nThe following is output of ESBMC describing the vulnerability\\n\\n```\\n{esbmc}\\n```\\n\\nFix the source code.\",\n",
    "    \"Fix the source code:\\n\\n```c\\n{source}\\n```\\n\\n```{esbmc}\\n```\\n\",\n",
    "]\n",
    "\n",
    "simple_prompts_flipped: list[str] = [\n",
    "    \"ESBMC output describes a memory vulnerability in the source code, the following is ESBMC output:\\n\\n```\\n{esbmc}\\n```\\n\\nThe following is the vulnerable source code:\\n\\n```c\\n{source}\\n```\\n\\nFix the source code.\",\n",
    "    \"Fix the source code:\\n\\n```\\n{esbmc}\\n```\\n\\n```c\\n{source}\\n```\\n\",\n",
    "]\n",
    "\n",
    "# Persona Prompts\n",
    "\n",
    "persona_prompt_no_esbmc: list[str] = [\n",
    "    \"You’re a {role}. You’ll be shown some C code. Repair the code and display it. The code is\\n\\n```c\\n{source}\\n```\\n\",\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown AI C code. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The code is\\n\\n```c\\n{source}\\n```\\n\"\n",
    "]\n",
    "\n",
    "persona_prompt: list[str] = [\n",
    "    \"You’re a {role}. You’ll be shown some C code, along with ESBMC output. Repair the code and display it. The code is\\n\\n```c\\n{source}\\n```\\n\\nThe ESBMC output is\\n\\n```\\n{esbmc}\\n```\\n\",\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The code is\\n\\n```c\\n{source}\\n```\\n\\nThe ESBMC output is\\n\\n```\\n{esbmc}\\n```\\n\",\n",
    "]\n",
    "\n",
    "persona_prompt_flipped: list[str] = [\n",
    "    \"You’re a {role}. You’ll be shown some C code, along with ESBMC output. Repair the code and display it. The ESBMC output is\\n\\n```\\n{esbmc}\\n```\\n\\nThe source code is\\n\\n```c\\n{source}\\n```\\n\",\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The ESBMC output is\\n\\n```\\n{esbmc}\\n```\\n\\nThe source code is\\n\\n```c\\n{source}\\n```\\n\",\n",
    "]\n",
    "\n",
    "# ESBMC-AI Prompts\n",
    "\n",
    "esbmc_ai_prompts: list[str] = [\n",
    "    \"You are an secure code generator that parses vulnerable source code, \"\n",
    "    \"and output from a program called ESBMC, which contains vulnerability information \"\n",
    "    \"about the source code. You should use the output from ESBMC to find the problem, \"\n",
    "    \"and correct the source code. ESBMC is always correct. You shall add a NULL check \"\n",
    "    \"for every heap allocation you make. From this point on, you can only reply in source code. \"\n",
    "    \"You shall only output source code as whole. The following text is the source code of the \"\n",
    "    \"program: \\n\\n```c\\n{source}\\n```\\n\\nThe following text is the output of ESBMC, reply OK if \"\n",
    "    \"you understand:\\n\\n```\\n{esbmc}```\\n\\nGenerate a correction for the source code provided. \"\n",
    "    \"Show the code only. Do not reply with acknowledgements.\"\n",
    "]\n",
    "\n",
    "all_prompts: list[str] = simple_prompts_no_esbmc + simple_prompts + simple_prompts_flipped + persona_prompt_no_esbmc + persona_prompt + persona_prompt_flipped + esbmc_ai_prompts\n",
    "\n",
    "persona_roles: list[str] = [\n",
    "    \"Programmer with 1 million years of experience\",\n",
    "    \"Senior software engineer\",\n",
    "    \"Automated code repair tool\",\n",
    "    \"Artificial intelligence that specializes in repairing C programs\",\n",
    "    \"The smartest human in the universe\",\n",
    "    \"Dog\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64917365-a4c3-4fc5-adcc-5417a3e40b78",
   "metadata": {},
   "source": [
    "# Experiment Execution\n",
    "\n",
    "The source code and the ESBMC output is too large for the LLM's context length. 3 strategies are proposed to see if they can alleviate the problem:\n",
    "\n",
    "1. Constant: Split by line or by character no strucutre (Brutal split)\n",
    "2. ~~Structural: Split semantically (function by function)~~\n",
    "3. Contextual: Split from failure and show code before\n",
    "\n",
    "#### Notation\n",
    "\n",
    "Let `L={l1, l2, l3, ..., ln}` be the set of all line lengths and where `n` is the number of lines in `C` and where `lx` is the length of the `x`th line in `C`. So `C[l1]` is the length first line and so on... `E` represents the length of the line with the error and `e` is the index of that line in `L`, such that `E=L[e]=le`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c79152-300f-4c1e-980d-0e5529dae348",
   "metadata": {},
   "source": [
    "### Combining Strategies\n",
    "\n",
    "The LLM response can be merged back into the full source code using the following strategies:\n",
    "\n",
    "1. Brutal replacement: input to the LLM are simply replaced by whatever code the LLM responds with.\n",
    "2. ~~Direct replacement: Ask the LLM to supply in a specific format the line(s) to replace. Then simply replace those lines.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592ff71a-668c-42d0-9bb5-841c4367f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch_brutal_replacement(source_code: str, patch: str, start: int, end: int) -> str:\n",
    "    \"\"\"End is non-inclusive. So to replace a single line, start and end are equal.\"\"\"\n",
    "    lines: list[str] = source_code.splitlines()\n",
    "    lines = lines[:start] + [patch] + lines[end+1:]\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02a871-a184-4bb0-8056-d8c0e4586afe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ~~Constant Splitting Strategy~~\n",
    "\n",
    "Constant splitting strategy splits the source code into constant sized tokens, then asks the LLM to repair each segment. The segment size is determined by using a percentage of the max tokens. The size of each segment is going to be `95%` in order to leave room for the counterexample.\n",
    "\n",
    "Calculate the segment boundaries like so:\n",
    "1. We want the largest `i` such that `S = Σ{i=0}{e}(L[i]<=TOKENS)`.\n",
    "2. The constraints of `S` are as follows: `0<=i<=n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a27881de-3e12-4422-b40a-b5157e0f4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "SEGMENT_TOKEN_PERCENT: float = 0.95\n",
    "\n",
    "def get_segments(lines: list[str]) -> list[str]:\n",
    "    \"\"\"Splits the lines into constant size segments using the `SEGMENT_TOKEN_PERCENT` and `MAX_TOKEN`\n",
    "    variable. Make sure the lines have their new lines still attached.\"\"\"\n",
    "    token_count: int = 0\n",
    "    segments: list[list[str]] = [[]]\n",
    "    for line in lines:\n",
    "        token_count += num_tokens_from_string(line)\n",
    "        if token_count >= SEGMENT_TOKEN_PERCENT * MAX_TOKENS:\n",
    "            # Start a new segment.\n",
    "            segments.append([])\n",
    "            token_count = 0\n",
    "        # Add line to latest segment\n",
    "        segments[-1].append(line)\n",
    "    # Combine segment lines (list of lines) into a complete string.\n",
    "    # Then return list of segments.\n",
    "    return list(\"\".join(segment) for segment in segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "273d2817-6cc2-4be1-b675-903efdaad718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "print_and_log()\n",
    "print_and_log(\"Running Constant Splitting Strategy\")\n",
    "\n",
    "# Loop through prompts\n",
    "for prompt_idx, prompt in enumerate(all_prompts):\n",
    "    print_and_log()\n",
    "    print_and_log(f\"Running new cycle with the following prompt ({prompt_idx}):\\n```\\n{prompt}\\n```\")\n",
    "    # Try all the roles\n",
    "    # Check if a {role} tag is in the prompt string and use roles in that case.\n",
    "    role_count: int\n",
    "    if \"{role}\" in prompt:\n",
    "        print_and_log(\"Notice: Prompt has roles. Will cycle roles.\")\n",
    "        role_count = len(persona_roles)\n",
    "    else:\n",
    "        print_and_log(\"Notice: Prompt has no roles. Roles will not be cycled or used.\")\n",
    "        role_count = 1\n",
    "        \n",
    "    # Loop through files\n",
    "    for idx, file_name_key in enumerate(data_samples.keys()):\n",
    "        print_and_log()\n",
    "        print_and_log(f\"Checkpoint {idx}: {file_name_key}\")\n",
    "        \n",
    "        source_code: str = data_samples[file_name_key]\n",
    "        esbmc_output: str = data_esbmc_output[file_name_key]\n",
    "\n",
    "        # Split the source code into lines to divide into segments.\n",
    "        lines: list[str] = source_code.splitlines(True)\n",
    "        # Divide into segments. Get back string segments.\n",
    "        source_code_segments: list[str] = get_segments(lines)\n",
    "        \n",
    "        # Loop through all the segments.\n",
    "        for segment_idx, sc_segment in enumerate(source_code_segments):\n",
    "            # Try all the roles, if no roles, then loop will execute once only.\n",
    "            for role_idx in range(role_count):\n",
    "                try:\n",
    "                    delta: float = time()\n",
    "                    # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "                    llm_output = run_sample(prompt, trimmed_sc, esbmc_output, all_prompts[role_idx])\n",
    "                    delta = time() - delta\n",
    "    \n",
    "                    print_and_log(f\"Duration: {delta}\")\n",
    "                    log_str(f\"Raw Response:\\n\\n{llm_output}\")\n",
    "                    \n",
    "                    llm_output = get_code_from_solution(llm_output)\n",
    "    \n",
    "                    # Save patch\n",
    "                    with open(f\"results/constant/{file_name_key}-{segment_idx}-{prompt}-{role_idx}\", \"w\") as file:\n",
    "                        file.write(llm_output)\n",
    "        \n",
    "                    # Stitch together patch\n",
    "                    patched_source: str = apply_patch_brutal_replacement(\n",
    "                        source_code,\n",
    "                        llm_output,\n",
    "                        segment_idx * constant_split_lines,\n",
    "                        (segment_idx + 1) * constant_split_lines\n",
    "                    )\n",
    "        \n",
    "                    # Save patched source\n",
    "                    with open(f\"samples-patched/constant/{file_name_key}-{segment_idx}-{prompt}-{role_idx}\", \"w\") as file:\n",
    "                        file.write(patched_source)\n",
    "                except Exception as e:\n",
    "                    print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "                finally:\n",
    "                    print_and_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885d8ed-1a44-46ab-b549-84013404348d",
   "metadata": {},
   "source": [
    "### Contextual Strategy\n",
    "\n",
    "Involves getting the line at which the error has occured along with a ratio split of the lines before/after. In this case chose `85%` before and `10%` as we want to give as much information of how the code looked before the error, however, still include some lines after for context.\n",
    "\n",
    "The following variables are declared:\n",
    "* `LTOKENS=MAX_TOKENS*0.85` - The window of tokens to keep before the error line.\n",
    "* `UTOKENS=MAX_TOKENS*0.10` - The window of tokens to keep after the error line.\n",
    "\n",
    "The lower bound line index is calculated like so:\n",
    "1. We want the largest `il` such that `S = Σ{il=0}{e}(L[e-il]<=LTOKENS)`.\n",
    "2. The constraints of `S` are as follows: `0<=il<=e` and `0<=L[e-S:e]<=LTOKENS`.\n",
    "\n",
    "Similarly, the upper bound line index is calculated like so:\n",
    "1. We want the largest `iu` such that `S = Σ{iu=0}{e}(L[e+iu]<=UTOKENS)`.\n",
    "2. The constraints of `S` are as follows: `0<=iu<=n-e` and `0<=L[e:e+Su]<=UTOKENS`.\n",
    "\n",
    "The combined window will be: `L[e-lu:e+iu]` which will fill `95%` of `MAX_TOKENS`, the other `5%` will be allocated to the ESBMC output's counterexample stack-trace (and/)or violated property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fcb51c72-caa8-4717-8af2-d57ce4217c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_code_err_line(esbmc_output: str) -> int:\n",
    "    # Find \"Violated property:\" string in ESBMC output\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    for ix, line in enumerate(lines):\n",
    "        if \"Violated property:\" == line:\n",
    "            pos_line: str = lines[ix+1]\n",
    "            pos_line_split: str = pos_line.split(\" \")\n",
    "            for iy, word in enumerate(pos_line_split):\n",
    "                if word == \"line\":\n",
    "                    # Get the line number\n",
    "                    return int(pos_line_split[iy+1])\n",
    "            raise Exception(f\"Could not find line in {file_name_key}\")\n",
    "    raise Exception(f'Could not find \"Violated property:\" in {file_name_key}')\n",
    "\n",
    "def get_lower_bound(source_code_lines: list[str], error_line: int, additional_tokens: int = 0) -> int:\n",
    "    \"\"\"Gets the lower index offset from the error line to include in the trimmed source code.\n",
    "    Make sure the lines have their new lines still attached.\"\"\"\n",
    "    # Base case where the first line is too big.\n",
    "    if num_tokens_from_string(source_code_lines[error_line]) >= LTOKENS:\n",
    "        return line_idx\n",
    "    # Count each line's tokens and sum them into token_counts.\n",
    "    token_counts: int = additional_tokens\n",
    "    for line_idx in range(error_line, -1, -1):\n",
    "        line: str = source_code_lines[line_idx]\n",
    "        token_counts += num_tokens_from_string(line)\n",
    "        # Get the largest i that is less than LTOKENS.\n",
    "        if token_counts >= LTOKENS:\n",
    "            return line_idx + 1\n",
    "    # if we run out of lines then use all.\n",
    "    return 0\n",
    "\n",
    "def get_upper_bound(source_code_lines: list[str], error_line: int, additional_tokens: int = 0) -> int:\n",
    "    \"\"\"Gets the upper index offset from the error line to include in the trimmed source code.\n",
    "    Make sure the lines have their new lines still attached.\"\"\"\n",
    "    # Base case where the first line is too big.\n",
    "    if num_tokens_from_string(source_code_lines[error_line]) >= UTOKENS:\n",
    "        return line_idx\n",
    "    # Count each line's tokens and sum them into token_counts.\n",
    "    token_counts: int = additional_tokens\n",
    "    for line_idx in range(error_line, len(source_code_lines)):\n",
    "        line: str = source_code_lines[line_idx]\n",
    "        token_counts += num_tokens_from_string(line)\n",
    "        # Get the largest i that is less than LTOKENS.\n",
    "        if token_counts >= UTOKENS:\n",
    "            return line_idx - 1\n",
    "    # if we run out of lines then use all.\n",
    "    return len(source_code_lines) - 1\n",
    "\n",
    "def get_esbmc_output_sized(esbmc_output: str) -> str:\n",
    "    \"\"\"Trims start of ESBMC output.\"\"\"\n",
    "    while num_tokens_from_string(esbmc_output) > MAX_ESBMC_OUTPUT:\n",
    "        size = num_tokens_from_string(esbmc_output)\n",
    "        esbmc_output = esbmc_output[size-MAX_ESBMC_OUTPUT:]\n",
    "    return esbmc_output\n",
    "\n",
    "# Max ESBMC output allowed.\n",
    "MAX_ESBMC_OUTPUT=1000\n",
    "# The amount of lines to include before/after the line with the error.\n",
    "LTOKENS=floor(MAX_TOKENS*0.9)\n",
    "# Extra lines to add for context after the line with the error.\n",
    "UTOKENS=floor(MAX_TOKENS*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28945fb-14a2-47a7-b219-8156338f800d",
   "metadata": {},
   "source": [
    "#### Experimental Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b13d90ae-2754-4df3-901a-0b00051dee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_sample(\n",
    "        prompt_idx: int, \n",
    "        role_idx: int,\n",
    "        esbmc_output_type: str, \n",
    "        file_idx: int) -> None:\n",
    "    prompt: str = all_prompts[prompt_idx]\n",
    "    file_name_key: str = sorted(data_samples.keys())[file_idx]\n",
    "    role: str = persona_roles[role_idx]\n",
    "    \n",
    "    # Name will be sorted by experimental order. Not filename as common experiments can be\n",
    "    # found near eachother.\n",
    "    file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_name}\")\n",
    "    \n",
    "    # Get CE or VP output for ESBMC.\n",
    "    esbmc_output: str\n",
    "    if esbmc_output_type == \"ce\":\n",
    "        esbmc_output = data_esbmc_output[file_name_key]\n",
    "    else:\n",
    "        esbmc_output = data_vp_output[file_name_key]\n",
    "\n",
    "    esbmc_output = get_esbmc_output_sized(esbmc_output)\n",
    "\n",
    "    source_code: str = data_samples[file_name_key]\n",
    "    source_code_lines: list[str] = source_code.splitlines(True)\n",
    "    \n",
    "    # Get the used ESBMC output length in order to calculate how to add it to the prompt template.\n",
    "    esbmc_output_token_len: int = num_tokens_from_string(esbmc_output)\n",
    "\n",
    "    # TODO If we get errors here pass full esbmc output instead of trimmed.\n",
    "    err_line: int = get_source_code_err_line(esbmc_output)\n",
    "\n",
    "    # Trim the source code in order to give it to the LLM.\n",
    "    lower_bound: int = get_lower_bound(source_code_lines, err_line, esbmc_output_token_len * 0.9)\n",
    "    # The upper bound is inclusive.\n",
    "    upper_bound: int = get_upper_bound(source_code_lines, err_line, esbmc_output_token_len * 0.1)\n",
    "    trimmed_sc: str = \"\".join(source_code_lines[lower_bound:upper_bound+1])\n",
    "    \n",
    "    try:\n",
    "        log_str(f\"LLM Raw Input:\\n{get_llm_message(prompt, trimmed_sc, esbmc_output, role)}\")\n",
    "        \n",
    "        delta: float = time()\n",
    "        # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "        llm_output_raw = run_sample(prompt, trimmed_sc, esbmc_output, role)\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Raw Response:\\n\\n{llm_output_raw}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        llm_output = get_code_from_solution(llm_output_raw)\n",
    "        log_str(f\"Extracted Code:\\n\\n{llm_output}\")\n",
    "        \n",
    "        # Save patch\n",
    "        with open(f\"results/{file_name}\", \"w\") as file:\n",
    "            file.write(llm_output)\n",
    "\n",
    "        # Stitch together patch\n",
    "        patched_source: str = apply_patch_brutal_replacement(source_code, llm_output, lower_bound, upper_bound)\n",
    "\n",
    "        # Save patched source\n",
    "        with open(f\"samples-patched/{file_name}\", \"w\") as file:\n",
    "            file.write(patched_source)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(\"progress.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d7573-1794-4313-88d1-567d2deee5f4",
   "metadata": {},
   "source": [
    "#### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935dde2-75f0-4741-a535-0215b698e103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1710094389.9336197: Running Contextual Strategy\n",
      "\n",
      "1710094389.9339364: Notice: Running new cycle with prompt (0)\n",
      "1710094389.933959: Notice: Prompt has no roles. Roles will not be cycled or used (0).\n",
      "\n",
      "1710094389.9341624: Notice: Checkpoint 0.0.ce.0.gcas_5_safe.c-amalgamation-149.c\n",
      "1710094395.2022262: Notice: Duration: 4.27614426612854\n",
      "\n",
      "\n",
      "1710094395.2030036: Notice: Checkpoint 0.0.ce.1.gcas_8_safe.c-amalgamation-6.c\n"
     ]
    }
   ],
   "source": [
    "print_and_log()\n",
    "print_and_log(\"Running Contextual Strategy\")\n",
    "\n",
    "# Loop through prompts\n",
    "for prompt_idx, prompt in enumerate(all_prompts):\n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Running new cycle with prompt ({prompt_idx})\")\n",
    "    # Try all the roles\n",
    "    # Check if a {role} tag is in the prompt string and use roles in that case.\n",
    "    role_count: int\n",
    "    if \"{role}\" in prompt:\n",
    "        print_and_log(\"Notice: Prompt has roles. Will cycle roles.\")\n",
    "        role_count = len(persona_roles)\n",
    "    else:\n",
    "        print_and_log(\"Notice: Prompt has no roles. Roles will not be cycled or used (0).\")\n",
    "        role_count = 1\n",
    "\n",
    "    # Loop through the different roles.\n",
    "    for role_idx in range(role_count):\n",
    "        # Loop through violated property ESBMC output and counterexample ESBMC output.\n",
    "        for esbmc_output_type in [\"ce\", \"vp\"]:\n",
    "            # Loop through files\n",
    "            for file_idx, file_name_key in enumerate(sorted(data_samples.keys())):\n",
    "                # Check if file has already been processed and skip.\n",
    "                if os.path.exists(\"progress.txt\"):\n",
    "                    with open(\"progress.txt\", \"r\") as file:\n",
    "                        progress_files: list[str] = file.read().splitlines()\n",
    "                        file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "                        if file_name in progress_files:\n",
    "                            log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                            continue\n",
    "\n",
    "                run_contextual_sample(\n",
    "                    prompt_idx=prompt_idx, \n",
    "                    role_idx=role_idx, \n",
    "                    file_idx=file_idx, \n",
    "                    esbmc_output_type=esbmc_output_type,\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76d6a183-f434-43a1-99ad-dca5331da8d0",
   "metadata": {},
   "source": [
    "# Improving the Initial Results\n",
    "\n",
    "The results were not satisfactory, so in order to improve the LLM performance we introduce the following steps:\n",
    "\n",
    "1. Compare with ESBMC-AI system message, maybe the success of ESBMC-AI is due to a good system message.\n",
    "2. Try an alternative experiment where we show the LLM the line that is wrong ONLY and ask it to fix it, along with the ESBMC violated property.\n",
    "3. Clang Feedback Improvements:\n",
    "    1. Pass the LLM patched samples to the Clang Compiler\n",
    "    2. Pass the feedback to the LLM, and try a new clean cycle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f00fc-7019-4bbc-8926-1832d05ec3ac",
   "metadata": {},
   "source": [
    "## 1. ESBMC-AI System Message\n",
    "\n",
    "Rerun experiments with the ESBMC-AI System Message. ESBMC-AI Prompts were added into the all_prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0172c9d-5d42-4b9d-90ee-a350dcff028a",
   "metadata": {},
   "source": [
    "## 2. Single Line Experiment\n",
    "\n",
    "Try an alternative experiment where we show the LLM the line that is wrong ONLY and ask it to fix it, along with the ESBMC violated property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ade641-0b11-4e29-9632-b22243977b7e",
   "metadata": {},
   "source": [
    "### Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f9691d-3497-4ef2-84d1-82d61bd656b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs: list[str] = [\"samples-patched-single\", \"results-single\"]\n",
    "\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e4d2c-3632-4661-b8ef-b57e9e0e8060",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47452889-26a8-40c1-9661-fa9e0217e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_sample_single_line(\n",
    "        prompt_idx: int, \n",
    "        role_idx: int,\n",
    "        esbmc_output_type: str, \n",
    "        file_idx: int) -> None:\n",
    "    prompt: str = all_prompts[prompt_idx]\n",
    "    file_name_key: str = sorted(data_samples.keys())[file_idx]\n",
    "    role: str = persona_roles[role_idx]\n",
    "    \n",
    "    # Name will be sorted by experimental order. Not filename as common experiments can be\n",
    "    # found near eachother.\n",
    "    file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_name}\")\n",
    "    \n",
    "    # Get CE or VP output for ESBMC.\n",
    "    esbmc_output: str\n",
    "    if esbmc_output_type == \"ce\":\n",
    "        esbmc_output = data_esbmc_output[file_name_key]\n",
    "    else:\n",
    "        esbmc_output = data_vp_output[file_name_key]\n",
    "\n",
    "    esbmc_output = get_esbmc_output_sized(esbmc_output)\n",
    "\n",
    "    source_code: str = data_samples[file_name_key]\n",
    "    \n",
    "    # Get the used ESBMC output length in order to calculate how to add it to the prompt template.\n",
    "    esbmc_output_token_len: int = num_tokens_from_string(esbmc_output)\n",
    "\n",
    "    # ESBMC reports errors starting from 0. To get the correct line, we need to use 0 based\n",
    "    # indexing. TODO If we get errors here pass full esbmc output instead of trimmed.\n",
    "    err_line: int = get_source_code_err_line(esbmc_output) - 1\n",
    "\n",
    "    # Trim the source code in order to give it to the LLM.\n",
    "    sc_line: str = source_code.splitlines(True)[err_line]\n",
    "    \n",
    "    try:\n",
    "        log_str(f\"LLM Raw Input:\\n{get_llm_message(prompt, sc_line, esbmc_output, role)}\")\n",
    "        \n",
    "        delta: float = time()\n",
    "        # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "        llm_output_raw = run_sample(prompt, sc_line, esbmc_output, role)\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Raw Response:\\n\\n{llm_output_raw}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        llm_output = get_code_from_solution(llm_output_raw)\n",
    "        log_str(f\"Extracted Code:\\n\\n{llm_output}\")\n",
    "        \n",
    "        # Save patch\n",
    "        with open(f\"results-single/{file_name}\", \"w\") as file:\n",
    "            file.write(llm_output)\n",
    "\n",
    "        # Stitch together patch\n",
    "        patched_source: str = apply_patch_brutal_replacement(source_code, llm_output, err_line, err_line)\n",
    "\n",
    "        # Save patched source\n",
    "        with open(f\"samples-patched-single/{file_name}\", \"w\") as file:\n",
    "            file.write(patched_source)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(\"progress-single.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7a90d-72ff-49ce-af63-e4879c4c7457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1710234368.5373101: Running Contextual Strategy: Single Line\n",
      "\n",
      "1710234368.5376346: Notice: Running new cycle with prompt (0)\n",
      "1710234368.5376482: Notice: Prompt has no roles. Roles will not be cycled or used (0).\n",
      "\n",
      "1710234368.5378327: Notice: Checkpoint 0.0.ce.0.gcas_5_safe.c-amalgamation-149.c\n",
      "1710234369.968499: Notice: Duration: 0.8299524784088135\n",
      "\n",
      "\n",
      "1710234369.9693882: Notice: Checkpoint 0.0.ce.1.gcas_8_safe.c-amalgamation-6.c\n",
      "1710234373.5855856: Notice: Duration: 3.614337682723999\n",
      "\n",
      "\n",
      "1710234373.7372694: Notice: Checkpoint 0.0.ce.2.robot_5_safe.c-amalgamation-124.c\n",
      "1710234375.635307: Notice: Duration: 1.8967316150665283\n",
      "\n",
      "\n",
      "1710234375.6364942: Notice: Checkpoint 0.0.ce.3.robot_5_safe.c-amalgamation-13.c\n",
      "1710234378.1564438: Notice: Duration: 2.518692970275879\n",
      "\n",
      "\n",
      "1710234378.1576607: Notice: Checkpoint 0.0.ce.4.robot_6_safe.c-amalgamation-46.c\n",
      "1710234382.5072443: Notice: Duration: 4.348337650299072\n",
      "\n",
      "\n",
      "1710234382.508448: Notice: Checkpoint 0.0.ce.5.robot_6_safe.c-amalgamation-49.c\n",
      "1710234385.5177946: Notice: Duration: 3.0080974102020264\n",
      "\n",
      "\n",
      "1710234385.5190265: Notice: Checkpoint 0.0.ce.6.robot_7_safe.c-amalgamation-31.c\n",
      "1710234388.9267638: Notice: Duration: 3.4064974784851074\n",
      "\n",
      "\n",
      "1710234388.928035: Notice: Checkpoint 0.0.ce.7.vdp_0_safe.c-amalgamation-13.c\n",
      "1710234391.1177733: Notice: Duration: 2.1889779567718506\n",
      "\n",
      "\n",
      "1710234391.1184475: Notice: Checkpoint 0.0.ce.8.vdp_0_safe.c-amalgamation-89.c\n",
      "1710234392.073029: Notice: Duration: 0.7498137950897217\n",
      "\n",
      "\n",
      "1710234392.0737097: Notice: Checkpoint 0.0.ce.9.vdp_1_safe.c-amalgamation-28.c\n"
     ]
    }
   ],
   "source": [
    "print_and_log()\n",
    "print_and_log(\"Running Contextual Strategy: Single Line\")\n",
    "\n",
    "# Loop through prompts\n",
    "for prompt_idx, prompt in enumerate(all_prompts):\n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Running new cycle with prompt ({prompt_idx})\")\n",
    "    # Try all the roles\n",
    "    # Check if a {role} tag is in the prompt string and use roles in that case.\n",
    "    role_count: int\n",
    "    if \"{role}\" in prompt:\n",
    "        print_and_log(\"Notice: Prompt has roles. Will cycle roles.\")\n",
    "        role_count = len(persona_roles)\n",
    "    else:\n",
    "        print_and_log(\"Notice: Prompt has no roles. Roles will not be cycled or used (0).\")\n",
    "        role_count = 1\n",
    "\n",
    "    # Loop through the different roles.\n",
    "    for role_idx in range(role_count):\n",
    "        # Loop through violated property ESBMC output and counterexample ESBMC output.\n",
    "        for esbmc_output_type in [\"ce\", \"vp\"]:\n",
    "            # Loop through files\n",
    "            for file_idx, file_name_key in enumerate(sorted(data_samples.keys())):\n",
    "                # Check if file has already been processed and skip.\n",
    "                if os.path.exists(\"progress-single.txt\"):\n",
    "                    with open(\"progress-single.txt\", \"r\") as file:\n",
    "                        progress_files: list[str] = file.read().splitlines()\n",
    "                        file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "                        if file_name in progress_files:\n",
    "                            log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                            continue\n",
    "\n",
    "                run_contextual_sample_single_line(\n",
    "                    prompt_idx=prompt_idx, \n",
    "                    role_idx=role_idx, \n",
    "                    file_idx=file_idx, \n",
    "                    esbmc_output_type=esbmc_output_type,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f1b74-238d-4c44-872a-c055f508c546",
   "metadata": {},
   "source": [
    "## 3. Clang Feedback To LLM\n",
    "\n",
    "Perform a second iteration fix where the LLM is provided Clang feedback and asked to repair it. The results in `samples-patched` will be used along with `esbmc_output_1` (meaning 1st attempt). The results will be placed in `results-2` and `samples-patched-2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a8b65-dd3b-46ba-ad21-68b215d08c3c",
   "metadata": {},
   "source": [
    "### Load ESBMC Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f2c01a47-da61-45a4-be84-768f2c980c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clang_file_keys: list[str] = sorted(os.listdir(f\"esbmc_output_1/\"))\n",
    "data_samples_1: dict[str, str] = {}\n",
    "data_esbmc_output_1: dict[str, str] = {}\n",
    "\n",
    "for file_name in clang_file_keys:\n",
    "    if not file_name.endswith(\".c\"):\n",
    "        continue\n",
    "    \n",
    "    # Read samples-patched (Generated previously)\n",
    "    with open(f\"samples-patched/{file_name}\", \"r\") as file:\n",
    "        data_samples_1[file_name] = file.read()\n",
    "\n",
    "    # Read esbmc_output_1 (Generated by running ./eval-esbmc.sh)\n",
    "    with open(f\"esbmc_output_1/{file_name}\", \"r\") as file:\n",
    "        data_esbmc_output_1[file_name] = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa2efba-79fe-4da6-8b5d-bd6cf234dd28",
   "metadata": {},
   "source": [
    "### Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5c759fd-4394-43b6-ab11-6bee510658c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs: list[str] = [\"samples-patched-2\", \"results-2\"]\n",
    "\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4ddf5-0188-411a-ba2e-67d7357fd646",
   "metadata": {},
   "source": [
    "### Get Error Line\n",
    "\n",
    "Clang reports errors differently, this method will be used to find the error line: `samples-patched/12.0.ce.36.cartpole_2_safe.c-amalgamation-43.c:177:1: error:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6d53775-1a2e-4f3a-916e-337414365f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_code_err_line_clang(esbmc_output: str, filepath: str) -> int:\n",
    "    \"\"\"Gets the error line reported in the clang output.\"\"\"\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    for ix, line in enumerate(lines):\n",
    "        # Find the first line containing a filename along with error.\n",
    "        line_split: list[str] = line.split(\":\")\n",
    "        # Check for the filename\n",
    "        if line_split[0] == filepath and \" error\" in line_split[3]:\n",
    "            return int(line_split[1])\n",
    "            \n",
    "    raise Exception(f'Could not find error line in {file_name_key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f2b9a-132f-40cf-889e-83be03b8675c",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8d3ff44-2637-4935-bab2-6e2bfcfd7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_sample_clang(\n",
    "        prompt_idx: int, \n",
    "        role_idx: int,\n",
    "        file_idx: int,\n",
    "        file_name_key: str) -> None:\n",
    "    prompt: str = all_prompts[prompt_idx]\n",
    "    role: str = persona_roles[role_idx]\n",
    "    \n",
    "    # Name will be sorted by experimental order. Not filename as common experiments can be\n",
    "    # found near eachother.\n",
    "    file_name: str = f\"{prompt_idx}.{role_idx}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_name}\")\n",
    "\n",
    "    esbmc_output: str = get_esbmc_output_sized(data_esbmc_output_1[file_name_key])\n",
    "\n",
    "    source_code: str = data_samples_1[file_name_key]\n",
    "    source_code_lines: list[str] = source_code.splitlines(True)\n",
    "    \n",
    "    # Get the used ESBMC output length in order to calculate how to add it to the prompt template.\n",
    "    esbmc_output_token_len: int = num_tokens_from_string(esbmc_output)\n",
    "\n",
    "    # 0 based, pass full ESBMC output to get error line\n",
    "    err_line: int = get_source_code_err_line_clang(data_esbmc_output_1[file_name_key], f\"samples-patched/{file_name_key}\") - 1\n",
    "\n",
    "    # Trim the source code in order to give it to the LLM.\n",
    "    lower_bound: int = get_lower_bound(source_code_lines, err_line, esbmc_output_token_len * 0.9)\n",
    "    # The upper bound is inclusive.\n",
    "    upper_bound: int = get_upper_bound(source_code_lines, err_line, esbmc_output_token_len * 0.1)\n",
    "    trimmed_sc: str = \"\".join(source_code_lines[lower_bound:upper_bound+1])\n",
    "    \n",
    "    try:\n",
    "        log_str(f\"LLM Raw Input:\\n{get_llm_message(prompt, trimmed_sc, esbmc_output, role)}\")\n",
    "        \n",
    "        delta: float = time()\n",
    "        # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "        llm_output_raw = run_sample(prompt, trimmed_sc, esbmc_output, role)\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Raw Response:\\n\\n{llm_output_raw}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        llm_output = get_code_from_solution(llm_output_raw)\n",
    "        log_str(f\"Extracted Code:\\n\\n{llm_output}\")\n",
    "        \n",
    "        # Save patch\n",
    "        with open(f\"results-2/{file_name}\", \"w\") as file:\n",
    "            file.write(llm_output)\n",
    "\n",
    "        # Stitch together patch\n",
    "        patched_source: str = apply_patch_brutal_replacement(source_code, llm_output, lower_bound, upper_bound)\n",
    "\n",
    "        # Save patched source\n",
    "        with open(f\"samples-patched-2/{file_name}\", \"w\") as file:\n",
    "            file.write(patched_source)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(\"progress-2.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f49e46-265b-40d8-bb52-48cde2f1f853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1710896262.191575: Running Contextual Strategy: 2nd Iteration Clang Assist\n",
      "\n",
      "1710896262.1919131: Notice: Checkpoint 0.0.0.0.0.ce.0.gcas_5_safe.c-amalgamation-149.c\n",
      "1710896283.7466295: Notice: Duration: 21.544837951660156\n",
      "\n",
      "\n",
      "1710896283.7472646: Notice: Checkpoint 0.0.1.0.0.ce.1.gcas_8_safe.c-amalgamation-6.c\n",
      "1710896285.7952905: Notice: Duration: 2.0375583171844482\n",
      "\n",
      "\n",
      "1710896285.7958443: Notice: Checkpoint 0.0.10.0.0.ce.10.vdp_2_safe.c-amalgamation-27.c\n",
      "1710896291.2389543: Notice: Duration: 5.439812660217285\n",
      "\n",
      "\n",
      "1710896291.2395148: Notice: Checkpoint 0.0.11.0.0.ce.11.vdp_5_safe.c-amalgamation-66.c\n",
      "1710896307.8892813: Notice: Duration: 16.64569330215454\n",
      "\n",
      "\n",
      "1710896307.8898926: Notice: Checkpoint 0.0.12.0.0.ce.12.vdp_7_safe.c-amalgamation-28.c\n",
      "1710896308.9325588: Notice: Duration: 1.0382611751556396\n",
      "\n",
      "\n",
      "1710896308.9331083: Notice: Checkpoint 0.0.13.0.0.ce.13.vdp_7_safe.c-amalgamation-30.c\n",
      "1710896313.6488652: Notice: Duration: 4.712406158447266\n",
      "\n",
      "\n",
      "1710896313.6494334: Notice: Checkpoint 0.0.14.0.0.ce.14.vdp_7_safe.c-amalgamation-74.c\n",
      "1710896314.1796734: Notice: Duration: 0.5277278423309326\n",
      "\n",
      "\n",
      "1710896314.1802151: Notice: Checkpoint 0.0.15.0.0.ce.15.cartpole_0_safe.c-amalgamation-74.c\n",
      "1710896329.6368062: Notice: Duration: 15.44460654258728\n",
      "\n",
      "\n",
      "1710896329.6376958: Notice: Checkpoint 0.0.16.0.0.ce.16.cartpole_10_safe.c-amalgamation-110.c\n"
     ]
    }
   ],
   "source": [
    "print_and_log()\n",
    "print_and_log(\"Running Contextual Strategy: 2nd Iteration Clang Assist\")\n",
    "\n",
    "# Loop through clang files\n",
    "for file_name_key in clang_file_keys:\n",
    "    file_name_split: list[str] = file_name_key.split(\".\")\n",
    "    \n",
    "    # Get prompt from file\n",
    "    prompt_idx: int = int(file_name_split[0])\n",
    "    # Get role from file\n",
    "    role_idx: int = int(file_name_split[1])\n",
    "    # Get CE/VP from file\n",
    "    esbmc_output_type: str = file_name_split[2]\n",
    "    # Get file_idx\n",
    "    file_idx: int = int(file_name_split[3])\n",
    "\n",
    "    # Check if file has already been processed and skip.\n",
    "    if os.path.exists(\"progress-2.txt\"):\n",
    "        with open(\"progress-2.txt\", \"r\") as file:\n",
    "            progress_files: list[str] = file.read().splitlines()\n",
    "            file_name: str = f\"{prompt_idx}.{role_idx}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "            if file_name in progress_files:\n",
    "                log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                continue\n",
    "\n",
    "    if \"VERIFICATION\" in data_esbmc_output_1[file_name_key]:\n",
    "        print_and_log(f\"Skipping {file_idx} {file_name_key} as it has VERIFICATION\")\n",
    "        continue\n",
    "\n",
    "    run_contextual_sample_clang(\n",
    "        prompt_idx=prompt_idx, \n",
    "        role_idx=role_idx, \n",
    "        file_idx=file_idx,\n",
    "        file_name_key=file_name_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f124f-62f1-48ea-b404-a22ec8336a71",
   "metadata": {},
   "source": [
    "# Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b1850cb-a436-40f0-a5e1-2bb136d9fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_apply_brutal_replacement_strategy (__main__.TestNotebook.test_apply_brutal_replacement_strategy) ... ok\n",
      "test_get_code_from_solution (__main__.TestNotebook.test_get_code_from_solution) ... ok\n",
      "test_get_esbmc_output_sized (__main__.TestNotebook.test_get_esbmc_output_sized) ... ok\n",
      "test_get_lower_bound (__main__.TestNotebook.test_get_lower_bound) ... ok\n",
      "test_get_source_code_err_line (__main__.TestNotebook.test_get_source_code_err_line) ... ok\n",
      "test_get_upper_bound (__main__.TestNotebook.test_get_upper_bound) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.746s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0xffff91ce2350>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    \n",
    "    def test_get_code_from_solution(self):\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:\\n\\n```c\\naaa\\n```\"), \"aaa\")\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:\\n\\n```\\nabc\\n```\"), \"abc\")\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:```abc\\n```\"), \"This is a code block:```abc\\n```\")\n",
    "\n",
    "    def test_apply_brutal_replacement_strategy(self):\n",
    "        text = \"\\n\".join([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "        answer = \"\\n\".join([\"a\", \"b\", \"1\", \"g\"])\n",
    "        self.assertEqual(apply_patch_brutal_replacement(text, \"1\", 2, 5), answer)\n",
    "        text = \"\\n\".join([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "        answer = \"\\n\".join([\"a\", \"b\", \"c\", \"1\", \"e\", \"f\", \"g\"])\n",
    "        self.assertEqual(apply_patch_brutal_replacement(text, \"1\", 3, 3), answer)\n",
    "\n",
    "    def test_get_source_code_err_line(self):\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_48_safe.c-amalgamation-6.c\"]), 323)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_92_safe.c-amalgamation-14.c\"]), 221)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_95_safe.c-amalgamation-80.c\"]), 285)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_26_safe.c-amalgamation-74.c\"]), 299)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reach_prob_density/robot_5_safe.c-amalgamation-13.c\"]), 350)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reach_prob_density/vdp_1_safe.c-amalgamation-28.c\"]), 247)\n",
    "\n",
    "    def test_get_lower_bound(self):\n",
    "        source_code: str = data_samples[\"reinforcement_learning/cartpole_48_safe.c-amalgamation-6.c\"]\n",
    "        source_code_lines: list[str] = source_code.splitlines(True)\n",
    "\n",
    "        # Test the additional tokens and if they affect the line.\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 0), 176)\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 500), 177)\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 1000), 178)\n",
    "        \n",
    "        # Test if the length is accounted for.\n",
    "        self.assertLess(num_tokens_from_string(source_code[174:323]), LTOKENS)\n",
    "        self.assertLess(num_tokens_from_string(source_code[175:323]), LTOKENS - 500)\n",
    "        self.assertLess(num_tokens_from_string(source_code[176:323]), LTOKENS - 1000)\n",
    "    \n",
    "    def test_get_upper_bound(self):\n",
    "        source_code: str = data_samples[\"reach_prob_density/robot_5_safe.c-amalgamation-13.c\"]\n",
    "        source_code_lines: list[str] = source_code.splitlines(True)\n",
    "        \n",
    "        # Test the additional tokens and if they affect the line.\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 0), 444)\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 500), 422)\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 1000), 379)\n",
    "\n",
    "        # Test if the length is accounted for.\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:444]), UTOKENS)\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:422]), UTOKENS - 500)\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:379]), UTOKENS - 1000)\n",
    "\n",
    "    def test_get_esbmc_output_sized(self):\n",
    "        esbmc_output: str = data_esbmc_output[\"reach_prob_density/gcas_5_safe.c-amalgamation-149.c\"]\n",
    "        self.assertGreater(num_tokens_from_string(esbmc_output), MAX_ESBMC_OUTPUT)\n",
    "        self.assertLessEqual(num_tokens_from_string(get_esbmc_output_sized(esbmc_output)), MAX_ESBMC_OUTPUT)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp2-c336cd1eea68617b4dc4fee9b93af9eb",
   "language": "python",
   "name": "wp2-c336cd1eea68617b4dc4fee9b93af9eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
